{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Movie Reviews pt.1 -- Basics\n",
    "\n",
    "When you have a large amount of movie reviews, how can you know whether they are complments or criticisms? Since the amount of dataset is large, you cannot annotate them one by one, but need to use natural language processing tools to classify the sentiment of the text. Especially in Python, powerful packages like nltk and scikit-learn can help us do the text classification. In this project, I made a sentiment analysis of movie reviews from the dataset of [reviews on imdb](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences) from the UCI Machine Learning Repository's Sentiment Labelled Sentences Data Set.\n",
    "\n",
    "## Text Preprocessing\n",
    "In this dataset, there are 1000 movie reviews, including 500 positive (compliments) and 500 negative (criticisms). For example, *'A very, very, very slow-moving, aimless movie about a distressed, drifting young man.'* is marked as a negative review. \n",
    "\n",
    "However, in the raw text, we can see many words do not contain important semantics. The numbers and punctuations appear a lot in our raw text but has do not express positive or negative sentiment. Therefore, we need to strip numbers and punctuations.\n",
    "\n",
    "To further clean the data, we need to stem the words, so that words with different inflections can be counted as same tokens, because they convey the same semantics. e.g. 'distress' and 'distressed' will both be stemmed as 'distress'.\n",
    "\n",
    "After text preprocessing, we have 2 list of data. 'labels' is the list of targets of our classification. 'preprocessed' is the features-to-be of classification. For sentences in 'preprocessed', we translate the raw text into completely unreadable text. For example, *'A very, very, very slow-moving, aimless movie about a distressed, drifting young man.'* is to preprocessed as *'a veri veri veri slow move aimless movi about a distress drift young man'*\n",
    "\n",
    "You may wonder that: we translate the raw text into these unreadable text because we want each token to convey important semantics. Then why not strip the stopwords because they do not convey important semantics but are very frequent, such as 'a' and 'about'? In the next feature extraction section, we are going to use TF-IDF to take care of those stop words\n",
    "\n",
    "## Feature Extraction\n",
    "After text preprocessing, we are going to extract the features from our cleaned data. We are going to use TF-IDF vectorizer as our word embedding to vectorize and normalize the text. \n",
    "\n",
    "TF-IDF stands for term frequency-inverse document frequency. It evaluates the importance of a token to a document in a corpus. TF-IDF makes the data our model because it normalizes the term frequency, or simply the word count. It also reduces the noise of stop words.\n",
    "    \n",
    "We are going to take a variant of TF-IDF in this case. The formula for regular TF-IDF is [here](http://www.tfidf.com/). Unlike the orgininal TF-IDF, we change to use sublinear_tf, replacing TF with WF = 1 + log(TF). This variant addresses the problem that [\"twenty occurrences of a term in a document do not truly carry twenty times the significance of a single occurrence.\"](https://nlp.stanford.edu/IR-book/html/htmledition/sublinear-tf-scaling-1.html) For example, in the example of our first review *'A very, very, very slow-moving, aimless movie about a distressed, drifting young man.'* 'very' appeared three times. Therefore, for our dataset, we need to apply Sublinear TF scaling. It drastically improves the accuracy of our models' prediction later.\n",
    "\n",
    "After feature extraction, we have Tf-IDF-weighted document-term matrix stored in Compressed Sparse Row format. Each target is the sentiment of this sentence. '1' means positive and '0' means negative. But to make the data fit our model, we need to split our data into features and targets. Scikit-learn's train_test_split to randomly shuffle the data and split them into training set and testing set. In this specific case, I will use 1/5 of the whole dataset of testing set and the rest 4/5 as training set. Here is the code for the whole preprocessing process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer    # stem the words\n",
    "from nltk.tokenize import word_tokenize # tokenize the sentences into tokens\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # vectorize the texts\n",
    "from sklearn.model_selection import train_test_split # split the testing and training sets\n",
    "\n",
    "def preprocess(path):\n",
    "    '''generate cleaned dataset\n",
    "    \n",
    "    Args:\n",
    "        path(string): the path of the file of testing data\n",
    "\n",
    "    Returns:\n",
    "        X_train (list): the list of features of training data\n",
    "        X_test (list): the list of features of test data\n",
    "        y_train (list): the list of targets of training data ('1' or '0')\n",
    "        y_test (list): the list of targets of training data ('1' or '0')\n",
    "    '''\n",
    "    \n",
    "    # text preprocessing: iterate through the original file and \n",
    "    with open(path, encoding='utf-8') as file:\n",
    "        # record all words and its label\n",
    "        labels = []\n",
    "        preprocessed = []\n",
    "        for line in file:\n",
    "            # get sentence and label\n",
    "            sentence, label = line.strip('\\n').split('\\t')\n",
    "            labels.append(int(label))\n",
    "            \n",
    "            # remove punctuation and numbers\n",
    "            for ch in punctuation+'0123456789':\n",
    "                sentence = sentence.replace(ch,' ')\n",
    "            # tokenize the words and stem them\n",
    "            words = []\n",
    "            for w in word_tokenize(sentence):\n",
    "                words.append(PorterStemmer().stem(w))\n",
    "            preprocessed.append(' '.join(words))\n",
    "    \n",
    "    # vectorize the texts\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', sublinear_tf=True)\n",
    "    X = vectorizer.fit_transform(preprocessed)\n",
    "    # split the testing and training sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess('imdb_labelled.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "We can train the models with the training set, let the models to classify the testing set, and rate the models' performances by checking its accuracy score and time consumption. Here is the code for the classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "\n",
    "def classify(clf, todense=False):\n",
    "    '''to classify the data using machine learning models\n",
    "    \n",
    "    Args:\n",
    "        clf: the model chosen to analyze the data\n",
    "        todense(bool): whether to make the sparse matrix dense\n",
    "        \n",
    "    '''\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    t = time()\n",
    "    if todense:\n",
    "        clf.fit(X_train.todense(), y_train)\n",
    "        y_pred = clf.predict(X_test.todense())\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "    print(f'Time cost of {str(clf)}: {round(time()-t,2)}s\\nThe accuracy of {str(clf)}: {accuracy_score(y_test,y_pred)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the target is categorical and dichotomous, the features do not have assumed distribution, the models we can use for text classification are Logistics Regression, Stochastic Gradient Descent Classifier (SGDClassifier), Support Vector Classifier (SVC) and Neural Network (MLPClassifier). Because our feature data is sparse, SVC and SGD are useful. Among 3 types of Naive Bayes Classifiers (Bernoulli, Multinomial and Gaussian), we need to choose Multinomial, because the features are normalized by TF-IDF. The features do not fit Gaussian nor Bernoulli distribution.\n",
    "\n",
    "I will examine the performance of each selected model below. In this part, I will not tune the parameters for each model, but will do it in future.\n",
    "\n",
    "We can technically use Linear Driscriminant Analysis too. However, it is computationally expensive to calculate sparse matrices like our feature data. The accuracy of this model is also low. Therefore, we will not consider LDA this time. Here is the performance of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of LinearDiscriminantAnalysis(): 0.79s\n",
      "The accuracy of LinearDiscriminantAnalysis(): 0.71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "classify(LinearDiscriminantAnalysis(),todense=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the performances of the selected models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of LogisticRegression(): 0.03s\n",
      "The accuracy of LogisticRegression(): 0.825\n",
      "\n",
      "Time cost of MultinomialNB(): 0.0s\n",
      "The accuracy of MultinomialNB(): 0.825\n",
      "\n",
      "Time cost of SVC(): 0.09s\n",
      "The accuracy of SVC(): 0.835\n",
      "\n",
      "Time cost of SGDClassifier(): 0.0s\n",
      "The accuracy of SGDClassifier(): 0.82\n",
      "\n",
      "Time cost of MLPClassifier(): 3.47s\n",
      "The accuracy of MLPClassifier(): 0.81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "for model in [LogisticRegression(), MultinomialNB(), SVC(), SGDClassifier(), MLPClassifier()]:\n",
    "    classify(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "While we want to improve the accuracy of our models' prediction, we also want overfitting avoided, so that we can use the models to predict other datasets. Building an ensemble method is the solution to this problem. For each review, we are going to let every selected model vote for its own prediction, and take the mode of all votes to generate an ensemble prediction. The selected models are Logistic Regression, MultinomialNB, SVC and SGD. Because Neural Networks need complicated tuning and are time-consuming, I will not include MLPClassifier into this ensembel Learning. From the accuracy score and the confusion matrix below, we can see that, though the time cost increased, the performance of the ensemble model is satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 0.12s\n",
      "Accuracy: 0.83\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statistics import mode\n",
    "def ensemble(models):\n",
    "    '''to ensemble the models and classify the data based on each model's vote\n",
    "    \n",
    "    Args:\n",
    "        models: the list of models chosen to analyze the data\n",
    "        \n",
    "    '''\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    t = time()\n",
    "    # iterate through all the models and collect all their predictions\n",
    "    y_preds = []\n",
    "    for clf in models:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_preds.append(clf.predict(X_test))\n",
    "    \n",
    "    # Count their votes and get the mode of each prediction as the decision\n",
    "    y_pred = []\n",
    "    for i in range(len(y_preds[0])):\n",
    "        y_pred.append(mode([y[i] for y in y_preds]))\n",
    "    print(f'Time cost: {round(time()-t,2)}s\\nAccuracy: {accuracy_score(y_test,y_pred)}\\n')\n",
    "    plot_confusion_matrix(clf, X_test, y_test, values_format = 'd',display_labels=['positive','negative'])\n",
    "\n",
    "ensemble([LogisticRegression(),MultinomialNB(),SVC(),SGDClassifier()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
