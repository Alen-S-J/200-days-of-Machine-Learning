{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Movie Reviews pt.2 -- LSA\n",
    "\n",
    " I made a sentiment analysis of movie reviews from the dataset of reviews on imdb. In the last part, I first preprocessed the text of all reviews into lowercase stemmed stokens with numbers and punctuations stripped. Then, I used TF-IDF as word-embedding to vectorize the all words into sparse matrix. Afterwards, I ran several selected machine-learning models to classify the features, the sparse matrix, and evaluated their performances.\n",
    "\n",
    "However, this was just the basics of sentiment analysis. Because we have a relatively small dataset (1000 entries), we do not need to consider the dimension of features. The dimension of features last time was 2317, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2317"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.get_shape()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if we have a large dataset, like a million entries? The size of 1,000,000 x 2,317 is a super large for a  sparse matrix. It requires a strong computing power to store it and run it. It can also be exceedingly time-consuming. Therefore, we need to reduce the dimensionality of features and speed up our machine-learning process with a little loss of accuracy. In this part, I will conduct LSA on the Sentiment Analysis.\n",
    "## LSA and SVD\n",
    "Latent Semantic Analysis (LSA) is a common word-embedding method used in Topic Modelling. On the other hand, it is also useful for text classification. In short, LSA is to perform Singular Value Decomposition(SVD) on the matrix after TD-IDF vectorization. If you are not familiar with TF-IDF, please refer to the Pt.1 of this study. SVD is a powerful matrix decomposition method used in Natural Language Processing. In NLP, we can always encounter a huge amount of dimension for our features. We can use SVD to select a small amount of those dimensions to have a truncated matrix to process machine-learning. (Here is an informative [tutorial of SVD](https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm))\n",
    "\n",
    "To briefly explain SVD, we can decompose the matrix A as\n",
    "\n",
    "$A = USV^T$\n",
    "\n",
    "The original matrix $A$ is a $nxp$ matrix. $U$ is an $nxn$ matrix, containing n left singular vectors. $V$ is a $pxp$ matrix, containing p right singular vectors. $S$ is an $nxp$ diagonal matrix containing singular values on its diagonal. The rest elements off the diagonal are 0. The singular values $\\sigma$ are lined up according to its value: $\\sigma 1$ > $\\sigma 2$ > ... > $\\sigma k$\n",
    "\n",
    "Among all those singular values, we can choose a small number of singular values we want. For example, I will choose first 100 among all 2317 singular values in this case, in order to significantly reduce the dimensionality. We will remain the first 100 left singular vectors in $U_k$, the first 100 singular values in the singular matrix $S_k$, and the first 100 right singular vectors in $V_k$, and multiply them to get the truncated matrix $A_k$ as:\n",
    "\n",
    "$U_k S_k V_k^T = A_k$\n",
    "\n",
    "In Python, we can use scikit-learn to get the truncated SVD, and normalize it to tranform the feature matrix. Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# performance SVD\n",
    "svd = TruncatedSVD(100)\n",
    "# performance LSA and normalization\n",
    "lsa = make_pipeline(svd, MinMaxScaler())\n",
    "X_lsa = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can integrate this snippet of code into the preprocess method used in [part.1](https://charliezcr.github.io/sa_p1.html) and transform the dataset. Here is the 2.0 version of preprocess function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer    # stem the words\n",
    "from nltk.tokenize import word_tokenize # tokenize the sentences into tokens\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # vectorize the texts\n",
    "from sklearn.model_selection import train_test_split # split the testing and training sets\n",
    "from sklearn.decomposition import TruncatedSVD # SVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess(path):\n",
    "    '''generate cleaned dataset\n",
    "    \n",
    "    Args:\n",
    "        path(string): the path of the file of testing data\n",
    "\n",
    "    Returns:\n",
    "        X_train (list): the list of features of training data\n",
    "        X_test (list): the list of features of test data\n",
    "        y_train (list): the list of targets of training data ('1' or '0')\n",
    "        y_test (list): the list of targets of training data ('1' or '0')\n",
    "    '''\n",
    "    \n",
    "    # text preprocessing: iterate through the original file and \n",
    "    with open(path, encoding='utf-8') as file:\n",
    "        # record all words and its label\n",
    "        labels = []\n",
    "        preprocessed = []\n",
    "        for line in file:\n",
    "            # get sentence and label\n",
    "            sentence, label = line.strip('\\n').split('\\t')\n",
    "            labels.append(int(label))\n",
    "            \n",
    "            # remove punctuation and numbers\n",
    "            for ch in punctuation+'0123456789':\n",
    "                sentence = sentence.replace(ch,' ')\n",
    "            # tokenize the words and stem them\n",
    "            words = []\n",
    "            for w in word_tokenize(sentence):\n",
    "                words.append(PorterStemmer().stem(w))\n",
    "            preprocessed.append(' '.join(words))\n",
    "    \n",
    "    # vectorize the texts by tfidf\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', sublinear_tf=True)\n",
    "    X_tfidf = vectorizer.fit_transform(preprocessed)\n",
    "    svd = TruncatedSVD(100)\n",
    "    # perform lsa\n",
    "    lsa = make_pipeline(svd, MinMaxScaler())\n",
    "    X_lsa = lsa.fit_transform(X_tfidf)\n",
    "    # split the testing and training sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_lsa, labels, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess('imdb_labelled.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "We can apply the data transfromed by LSA to the machine-learning models and monitor the change in their performance. Remember that in part.1, the result for Linear Discriminant Analysis was:\n",
    ">Time cost of LinearDiscriminantAnalysis(): 0.79s<br>\n",
    "The accuracy of LinearDiscriminantAnalysis(): 0.71\n",
    "\n",
    "Now, we have our data's dimensionality significantly reduced. We should expect the time cost to be drastically improved this time. Also, we do not even need to make the data dense this time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of LinearDiscriminantAnalysis(): 0.05s\n",
      "The accuracy of LinearDiscriminantAnalysis(): 0.73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "classify(LinearDiscriminantAnalysis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just reduced the time cost from 0.79s to 0.05s. This is a giant leap as for speed!\n",
    "\n",
    "Remember that last time, we also tried Logistic Regression, MultinomialNB, SVC, SGD and MLP Classifiers. The performance was:\n",
    ">Time cost of LogisticRegression(): 0.03s<br>\n",
    "The accuracy of LogisticRegression(): 0.825<br>\n",
    "<br>\n",
    "Time cost of MultinomialNB(): 0.0s<br>\n",
    "The accuracy of MultinomialNB(): 0.825<br>\n",
    "<br>\n",
    "Time cost of SVC(): 0.09s<br>\n",
    "The accuracy of SVC(): 0.835<br>\n",
    "<br>\n",
    "Time cost of SGDClassifier(): 0.0s<br>\n",
    "The accuracy of SGDClassifier(): 0.82<br>\n",
    "<br>\n",
    "Time cost of MLPClassifier(): 3.47s<br>\n",
    "The accuracy of MLPClassifier(): 0.81<br>\n",
    "\n",
    "We can try all those models and observe their performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of LogisticRegression(): 0.08s\n",
      "The accuracy of LogisticRegression(): 0.76\n",
      "\n",
      "Time cost of MultinomialNB(): 0.0s\n",
      "The accuracy of MultinomialNB(): 0.775\n",
      "\n",
      "Time cost of SVC(): 0.08s\n",
      "The accuracy of SVC(): 0.745\n",
      "\n",
      "Time cost of SGDClassifier(): 0.01s\n",
      "The accuracy of SGDClassifier(): 0.75\n",
      "\n",
      "Time cost of MLPClassifier(): 0.68s\n",
      "The accuracy of MLPClassifier(): 0.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "for model in [LogisticRegression(), MultinomialNB(), SVC(), SGDClassifier(), MLPClassifier()]:\n",
    "    classify(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even though the accuracy decreases a little for all those model, the speed is accelerated. The Time cost is significantly reduced for the complicated model MLP classifier. Therefore, MLP classifer and Linear Discriminant Classifier can be included in the ensemble classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 1.03s\n",
      "Accuracy: 0.78\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble([LinearDiscriminantAnalysis(),LogisticRegression(),MultinomialNB(),SVC(),SGDClassifier(),MLPClassifier()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
