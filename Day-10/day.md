# Day 10: Improving Model Performance

## Morning: Feature Engineering

### Understanding Feature Engineering Techniques:

- **Handling Categorical Variables:**
  - Learn about one-hot encoding, label encoding, and when to use each technique for handling categorical data.
  - Understand the importance of avoiding ordinal assumptions for categorical variables.

- **Creating Interaction Terms:**
  - Learn how to create interaction terms by combining features, providing the model with additional context.
  - Experiment with combining relevant features to see how it affects the model's performance.

- **Polynomial Features:**
  - Understand the concept of adding polynomial features to capture nonlinear relationships in the data.
  - Implement polynomial feature transformation and observe how it impacts the model's flexibility.

### Implementing Feature Engineering Techniques:

- Using your chosen programming language, apply the learned techniques to preprocess and engineer features in your dataset.
- Use a real dataset and apply one-hot encoding, create interaction terms, and experiment with polynomial features.

## Afternoon: Regularization and Hyperparameters

### Understanding Regularization:

- **LASSO and Ridge Regression:**
  - Learn in detail about LASSO (L1 regularization) and Ridge (L2 regularization) and their effect on the model.
  - Understand how they help prevent overfitting by penalizing large coefficients.

- **Hyperparameters:**
  - Learn about hyperparameters in the context of machine learning models.
  - Understand common hyperparameters for linear regression (e.g., apha for regularization) and their impact on the model.

### Experimenting with Regularization:

- Implement LASSO and Ridge regression with different values of regularization parameter (α).
- Observe how the choice of α affects the model's complexity and performance.

### Model Evaluation and Comparison:

- Evaluate models using metrics like mean squared error, R-squared, or any other relevant metrics suitable for your dataset.
- Compare the performance of models with and without regularization and varying levels of hyperparameters.
