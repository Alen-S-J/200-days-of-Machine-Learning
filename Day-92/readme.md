
### 1. Semi-Supervised Learning (SSL):
Semi-Supervised Learning is a machine learning paradigm where both labeled and unlabeled data are used for training. The fundamental idea is that incorporating a large amount of unlabeled data can improve the model's performance compared to using only labeled data.

### 2. Contrastive Learning:
Contrastive Learning aims to learn representations by contrasting positive pairs (similar samples) and negative pairs (dissimilar samples). It encourages the model to bring similar instances closer in the embedding space while pushing dissimilar instances apart.

### 3. Autoencoders:
Autoencoders are neural network architectures used for unsupervised learning of efficient data codings. They consist of an encoder network that compresses the input data into a latent space representation and a decoder network that attempts to reconstruct the input from this representation.

### 4. Predictive Learning:
Predictive Learning in SSL involves using predictions from unlabeled data to improve the model's performance. The model is trained to make predictions about unlabeled data points based on the learned representation.




